{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files\n",
    "\n",
    "# one-hot encode peptide chains\n",
    "\n",
    "# normalize in each peptide column\n",
    "\n",
    "# one-hot encode visit months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sup_clin_df = pd.read_csv('data/supplemental_clinical_data.csv')\n",
    "len(sup_clin_df['patient_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_month_5 = sup_clin_df[sup_clin_df['visit_month'] != 5]\n",
    "visits = no_month_5.visit_month.unique()\n",
    "visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = no_month_5.groupby('patient_id').size()\n",
    "remove = list(counts[counts<2].index)\n",
    "\n",
    "mask = ~no_month_5['patient_id'].isin(remove)\n",
    "ts_data = no_month_5[mask]\n",
    "\n",
    "ts_data = ts_data.rename(columns={'upd23b_clinical_state_on_medication': 'on_Levodopa'})\n",
    "\n",
    "ts_data.loc[:, 'on_Levodopa'] = ts_data['on_Levodopa'].fillna(0)\n",
    "ts_data.loc[:, 'on_Levodopa'] = ts_data['on_Levodopa'].replace('On', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_data(patient_data):\n",
    "    # create an empty DataFrame with the desired structure\n",
    "    visit_months = [0, 6, 12, 18, 24, 30, 36]\n",
    "    data = pd.DataFrame(np.nan, index=visit_months, columns=['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'on_Levodopa'])\n",
    "    \n",
    "    # fill the data DataFrame with data from patient_data based on visit_month\n",
    "    for _, row in patient_data.iterrows():\n",
    "        visit_month = row['visit_month']\n",
    "        if visit_month in visit_months:\n",
    "            data.loc[visit_month] = row[['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'on_Levodopa']].values\n",
    "    \n",
    "    # forward fill missing values down the rows\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # reset the index and rename the column to 'visit_month'\n",
    "    data.reset_index(inplace=True)\n",
    "    data.rename(columns={'index': 'visit_month'}, inplace=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_data(ts_data[ts_data['patient_id']==337]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming ts_data is a DataFrame with the time series data for all patients\n",
    "\n",
    "# Create a dictionary to store patient data\n",
    "patient_dict = {}\n",
    "for id in ts_data['patient_id'].unique():\n",
    "    # Get data for the current patient\n",
    "    patient_data = ts_data[ts_data['patient_id'] == id]\n",
    "    # Expand data to include all timesteps for each patient\n",
    "    patient_dict[id] = extract_data(patient_data)\n",
    "\n",
    "# Convert the dictionary to a list of DataFrames, dropping 'patient_id' and 'visit_month' columns\n",
    "patient_data_list = [df.drop(columns=['visit_month']).values for df in patient_dict.values()]\n",
    "\n",
    "# Stack the DataFrames along a new axis to create a 3D array\n",
    "patient_data_array = np.stack(patient_data_list, axis=0)\n",
    "\n",
    "# The resulting array will have the shape (number_of_patients, number_of_timesteps, number_of_features)\n",
    "print(patient_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "label_column = patient_data_array[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_data_array, label_column, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split test set into test and validation sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the train, test, and validation sets\n",
    "X_train = X_train.reshape(-1, 35)\n",
    "X_test = X_test.reshape(-1, 35)\n",
    "X_val = X_val.reshape(-1, 35)\n",
    "\n",
    "# Print the new shapes of the input arrays\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('X_val shape:', X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(Dense(64, activation='relu', input_shape=(35,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model with appropriate loss function, optimizer and metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-amp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
